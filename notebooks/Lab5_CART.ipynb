{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e894750d-e1ea-4f6f-a93a-7ae09ae2ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dbdb0b64-7ffe-4610-b45a-a5db8a819479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_metrics(y_test, y_pred):\n",
    "    print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "    print(f'MSE: {mean_squared_error(y_test, y_pred)}')\n",
    "    print(f'RMSE: {(mean_squared_error(y_test, y_pred))**0.5}')\n",
    "    print(f'MAPE: {(mean_absolute_percentage_error(y_test, y_pred))**0.5}')\n",
    "    print(f'R^2: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e8ccf766-0526-4221-b2b7-861ab717059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CART:\n",
    "\n",
    "    def __init__(self,\n",
    "                 max_depth: int | None = None, \n",
    "                 min_samples_split: int = 2,\n",
    "                 classification: bool = False,\n",
    "                 ) -> None:\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.classification = classification\n",
    "\n",
    "    class Node:\n",
    "        def __init__(self, \n",
    "                     feature: int | None = None, \n",
    "                     threshold: float | None = None, \n",
    "                     value: int | float | None = None, \n",
    "                     left = None, right = None\n",
    "                     ) -> None:\n",
    "                self.feature = feature\n",
    "                self.threshold = threshold\n",
    "                self.value = value\n",
    "                self.left = left\n",
    "                self.right = right\n",
    "\n",
    "    def _entropy(self, Y: np.ndarray) -> float:\n",
    "        \"\"\"Находит энтропию столбца\"\"\"\n",
    "        probabilities = np.array(list(Counter(Y).values())) / len(Y)\n",
    "        return -np.sum(probabilities * np.log2(probabilities))\n",
    "    \n",
    "    def _MSE(self, Y: np.ndarray) -> float:\n",
    "        \"\"\"Находит среднеквадратичную ошибку столбца\"\"\"\n",
    "        return np.mean((Y - np.mean(Y))**2)\n",
    "\n",
    "    def _split_dataset(self, X: np.ndarray, Y: np.ndarray, feature: int, threshold: float):\n",
    "        \"\"\"\n",
    "        Разделяет датасеты на левую и правую подвыборку \n",
    "        по признаку feature на основе порога threshold\n",
    "        \"\"\"\n",
    "        left_indexes = np.where(X[:,feature] <= threshold)[0]\n",
    "        right_indexes = np.where(X[:,feature] > threshold)[0]\n",
    "        return X[left_indexes], Y[left_indexes], X[right_indexes], Y[right_indexes]\n",
    "\n",
    "    def _find_best_split(self, X: np.ndarray, Y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Находит лучшее разделение данных на левую и правую подвыборку\n",
    "        \"\"\"\n",
    "        best_feature, best_threshold, best_score = None, None, np.inf\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:,feature])\n",
    "            for threshold in thresholds:\n",
    "                x_left, y_left, x_right, y_right = self._split_dataset(X,Y,feature,threshold)\n",
    "\n",
    "                if self.classification:\n",
    "                    score = (len(y_left) * self._entropy(y_left) + \\\n",
    "                             len(y_right) * self._entropy(y_right)) / len(Y)\n",
    "                else:\n",
    "                    score = (len(y_left) * self._MSE(y_left) + \\\n",
    "                             len(y_right) * self._MSE(y_right)) / len(Y)\n",
    "                if score < best_score:\n",
    "                    best_feature, best_threshold, best_score = feature, threshold, score\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _build_tree(self, X: np.ndarray, Y: np.ndarray, depth=0) -> Node:\n",
    "        if depth == self.max_depth or len(X) < self.min_samples_split:\n",
    "            if self.classification:\n",
    "                return self.Node(value=Counter(Y).most_common(1)[0][0])\n",
    "            else:\n",
    "                return self.Node(value=np.mean(Y))\n",
    "            \n",
    "        feature, threshold = self._find_best_split(X,Y)\n",
    "        x_left, y_left, x_right, y_right = self._split_dataset(X,Y,feature,threshold)\n",
    "        left_child = self._build_tree(x_left,y_left,depth=depth + 1)\n",
    "        right_child = self._build_tree(x_right,y_right,depth=depth + 1)\n",
    "\n",
    "        return self.Node(feature=feature,threshold=threshold,left=left_child,right=right_child)\n",
    "\n",
    "    def fit(self, X: np.ndarray, Y: np.ndarray):\n",
    "        self.tree_ = self._build_tree(X,Y)\n",
    "        return self\n",
    "\n",
    "    def _predict_single(self, x: np.ndarray, node: Node) -> int | float:\n",
    "        if node.feature is None:\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._predict_single(x, node.left)\n",
    "        else:\n",
    "            return self._predict_single(x, node.right)\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> list[float] | list[int]:\n",
    "        y_pred = np.zeros(len(X), dtype=int if self.classification else float)\n",
    "        for i in range(X.shape[0]):\n",
    "            y_pred[i] = self._predict_single(X[i], self.tree_)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1cb51c0c-c64d-4db0-b03d-6d9f4ebb8117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x,y = make_classification(\n",
    "    n_samples=2000,\n",
    "    n_clusters_per_class=1,\n",
    "    n_features=4,\n",
    "    n_classes=3\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1bcb2592-ab0a-4fe9-b49e-f736733e0ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       129\n",
      "           1       0.96      0.95      0.96       137\n",
      "           2       0.99      0.99      0.99       134\n",
      "\n",
      "    accuracy                           0.96       400\n",
      "   macro avg       0.96      0.96      0.96       400\n",
      "weighted avg       0.96      0.96      0.96       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "crt = CART(classification=True)\n",
    "crt.fit(x_train,y_train)\n",
    "predict = crt.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "098fff5e-09db-4a04-bef9-04579f34421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95       129\n",
      "           1       0.98      0.93      0.95       137\n",
      "           2       1.00      0.99      0.99       134\n",
      "\n",
      "    accuracy                           0.96       400\n",
      "   macro avg       0.97      0.97      0.97       400\n",
      "weighted avg       0.97      0.96      0.97       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train,y_train)\n",
    "\n",
    "pred = dt.predict(x_test)\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8394fcd1-22ec-4389-a793-d782395a1ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "x,y = make_regression(\n",
    "    n_samples=2000,\n",
    "    n_features=4\n",
    ")\n",
    "\n",
    "x_train, x_test,  y_train,  y_test = train_test_split(x,y, test_size=0.2,random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "57ac9b7f-6dd6-40aa-9479-ff0e084b9b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sviat\\Desktop\\mashobych\\venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Sviat\\Desktop\\mashobych\\venv\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 15.280133349409306\n",
      "MSE: 384.859274878438\n",
      "RMSE: 19.617830534451\n",
      "MAPE: 0.9248141497033697\n",
      "R^2: 0.9462971646342391\n"
     ]
    }
   ],
   "source": [
    "crt = CART()\n",
    "crt.fit(x_train,y_train)\n",
    "predict = crt.predict(x_test)\n",
    "regression_metrics(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dc0a8d8e-9c36-42cf-ad02-21cff54597c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 14.601753557748339\n",
      "MSE: 400.112947822617\n",
      "RMSE: 20.002823496262145\n",
      "MAPE: 0.8912937679269818\n",
      "R^2: 0.9441686840692244\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(random_state = 0)\n",
    "dt.fit(x_train,y_train)\n",
    "\n",
    "predict = dt.predict(x_test)\n",
    "regression_metrics(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632822aa-020f-4cfd-965f-260d5ab34275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
